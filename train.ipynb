{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "Main file for training Yolo model on Pascal VOC and COCO dataset<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import YOLOv3\n",
    "from tqdm import tqdm\n",
    "from utils import (\n",
    "    mean_average_precision,\n",
    "    cells_to_bboxes,\n",
    "    get_evaluation_bboxes,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    "    check_class_accuracy,\n",
    "    get_loaders,\n",
    "    plot_couple_examples\n",
    ")\n",
    "from loss import YoloLoss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn, scaled_anchors):\n",
    "#     loop = tqdm(train_loader, leave=True)\n",
    "    losses = []\n",
    "    for (x, y) in train_loader:\n",
    "        x = x.to(config.DEVICE)\n",
    "        y0, y1, y2 = (\n",
    "            y[0].to(config.DEVICE),\n",
    "            y[1].to(config.DEVICE),\n",
    "            y[2].to(config.DEVICE),\n",
    "        )\n",
    "#         print(batch_idx)\n",
    "        for tensor in x:\n",
    "            print(tensor.size())\n",
    "        \n",
    "        out=model(x)\n",
    "        loss = (\n",
    "            loss_fn(out[0], y0, scaled_anchors[0])\n",
    "            + loss_fn(out[1], y1, scaled_anchors[1])\n",
    "            + loss_fn(out[2], y2, scaled_anchors[2])\n",
    "        )\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress bar\n",
    "        mean_loss = sum(losses) / len(losses)\n",
    "        loop.set_postfix(loss=mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model = YOLOv3(num_classes=config.NUM_CLASSES).to(config.DEVICE)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY\n",
    "    )\n",
    "    loss_fn = YoloLoss()\n",
    "    train_loader, test_loader, train_eval_loader = get_loaders(\n",
    "        train_csv_path=config.DATASET + \"/8examples.csv\", test_csv_path=config.DATASET + \"/8examples.csv\"\n",
    "    )\n",
    "    #if config.LOAD_MODEL:\n",
    "        #load_checkpoint(\n",
    "            #config.CHECKPOINT_FILE, model, optimizer, config.LEARNING_RATE\n",
    "        #)\n",
    "    scaled_anchors = (\n",
    "        torch.tensor(config.ANCHORS)\n",
    "        * torch.tensor(config.S).unsqueeze(1).unsqueeze(1).repeat(1, 3, 2)\n",
    "    ).to(config.DEVICE)\n",
    "    for epoch in range(config.NUM_EPOCHS):\n",
    "        #plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\n",
    "        train_fn(train_loader, model, optimizer, loss_fn, scaled_anchors)\n",
    "\n",
    "        #if config.SAVE_MODEL:\n",
    "        #    save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")\n",
    "\n",
    "        #print(f\"Currently epoch {epoch}\")\n",
    "        #print(\"On Train Eval loader:\")\n",
    "        #print(\"On Train loader:\")\n",
    "        #check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\n",
    "        if epoch > 0 and epoch % 3 == 0:\n",
    "            check_class_accuracy(model, test_loader, threshold=config.CONF_THRESHOLD)\n",
    "            pred_boxes, true_boxes = get_evaluation_bboxes(\n",
    "                test_loader,\n",
    "                model,\n",
    "                iou_threshold=config.NMS_IOU_THRESH,\n",
    "                anchors=config.ANCHORS,\n",
    "                threshold=config.CONF_THRESHOLD,\n",
    "            )\n",
    "            mapval = mean_average_precision(\n",
    "                pred_boxes,\n",
    "                true_boxes,\n",
    "                iou_threshold=config.MAP_IOU_THRESH,\n",
    "                box_format=\"midpoint\",\n",
    "                num_classes=config.NUM_CLASSES,\n",
    "            )\n",
    "            print(f\"MAP: {mapval.item()}\")\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n",
      "torch.Size([3, 416, 416])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [62]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m scaled_anchors \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     15\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtensor(config\u001b[38;5;241m.\u001b[39mANCHORS)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(config\u001b[38;5;241m.\u001b[39mS)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     17\u001b[0m )\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mDEVICE)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mNUM_EPOCHS):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;66;03m#plot_couple_examples(model, test_loader, 0.6, 0.5, scaled_anchors)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_anchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#if config.SAVE_MODEL:\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#    save_checkpoint(model, optimizer, filename=f\"checkpoint.pth.tar\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m#print(\"On Train loader:\")\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;66;03m#check_class_accuracy(model, train_loader, threshold=config.CONF_THRESHOLD)\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [60]\u001b[0m, in \u001b[0;36mtrain_fn\u001b[1;34m(train_loader, model, optimizer, loss_fn, scaled_anchors)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tensor\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m     15\u001b[0m out\u001b[38;5;241m=\u001b[39mmodel(x)\n\u001b[0;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     17\u001b[0m     loss_fn(out[\u001b[38;5;241m0\u001b[39m], y0, scaled_anchors[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m     \u001b[38;5;241m+\u001b[39m loss_fn(\u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m, y1, scaled_anchors[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;241m+\u001b[39m loss_fn(out[\u001b[38;5;241m2\u001b[39m], y2, scaled_anchors[\u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     20\u001b[0m )\n\u001b[0;32m     22\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "data = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "targets = torch.tensor([0, 1, 0])\n",
    "dataset = TensorDataset(data, targets)\n",
    "\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for batch_data, batch_targets in dataloader:\n",
    "    print(\"Batch data:\")\n",
    "    print(batch_data)\n",
    "    print(\"Batch targets:\")\n",
    "    print(batch_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
